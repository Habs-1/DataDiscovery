---
title: "Lab02 Brandon Habschied"
output:
  pdf_document: default
---
```{r}

Auto <- read.csv("C:/Users/brand/OneDrive/Desktop/School/DataDrivenDiscovery/Labs/Lab2/Auto.csv")
View(Auto)
Auto <- na.omit(Auto)
# str(Auto) 
# convert horsepower from char to double so it can be in the scatterplot
Auto$horsepower <- as.numeric(Auto$horsepower)
# scatterplot the numerical variables only
Auto_num <- Auto[, -ncol(Auto)]
pairs(Auto_num)
round(cor(Auto_num), digits = 3)
linReg <- lm(mpg ~ . , data = Auto_num)
summary(linReg)
#
# 1. There is a relationship between the predictors and the response as noted by
# the large F statistic of 252.4 and the extremely small p-value of 2.2e-16
#
# 2. The predictors that appear to have significantly significant relationships
# are the ones with the extremely small p-values:
# weight, year, origin, displacement
#
# 3.The coefficient for year is 0.75 which suggests that each year, newer 
# vehicles' mpg will increase by .75 should all other variables stay the same. 
#
par(mfrow=c(2,2))
plot(linReg)

# There are a few unusually large outliers found on the residual plots, 
# 327,323, 336 stand out immediately. The QQ Residuals also has a cluster of 
# unusually large outliers. The leverage plot has a specific instance 14 with 
# an abnormally large leverage.
linReg2 <- lm(mpg ~ weight * year, data = Auto_num)
summary(linReg2)
plot(linReg2)

linReg3 <- lm(mpg ~ log(weight), data = Auto_num)
summary(linReg3)
plot(linReg3)

linReg4 <- lm(mpg ~ sqrt(weight), data = Auto_num)
summary(linReg4)
plot(linReg4)


par(mfrow=c(1,1))
# The interactions I tested above all seem to be statistically significant as
# they all have very small p-values and large F statistics of 
# 650, 967, and 935. Using the different interactions caused the leverage 
# line of best fit to be more aligned with cook's distance.

# PART 2
library(ISLR)
data("Carseats")
str(Carseats)
head(Carseats)
mReg <- lm(Sales ~ Price + Urban + US, data = Carseats)
summary(mReg)
# The coefficient for price being -0.054 suggests that for every increase in 
# in price by 1, sales will drop by 0.054. The coefficient for Urban of 
# -0.0219 suggests that a carseat in an urban setting (1) will have 0.0219 less
# sales than one in a non-urban setting (0). The coefficient for US suggests that a
# carseat made in the US (1) is likely to have 1.2 more sale units than one not
# made in the US (0). 
#
# C) Sales = 13.043 + (-0.054 * Price) + (-0.219 * Urban) + (1.2 * US) + error
# 
# D) We can reject the null hypothesis for the predictors Price and US due to 
# their extremely low p-values
# e) 
mReg2 <- lm(Sales ~ Price + US, data = Carseats)
summary(mReg2)
# f) The models above have RSE values that are close to 0, which indicates a 
# good fit for the data. Additionally, they both have relatively low F stats
# which indicates that the model is statistically significant. 
#
# g) using mReg2 from e) we can determine a 95% confidence interval using 1.96 
# as our critical value.

cat("Sales 95% CI: [", 13.03079 - 1.96 * 0.63098, ",", 13.03079 + 1.96 * 0.63098, "]")

cat("Price 95% CI: [", -0.05448 - 1.96 * 0.00523, ",", -0.05448 + 1.96 * 0.00523, "]")

cat("US 95% CI: [", 1.19964 - 1.96 * 0.25846, ",", 1.19964 + 1.96 * 0.25846, "]")

```
